{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTtgAV8RtWiO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qns5kcqhtSK4"
      },
      "outputs": [],
      "source": [
        "def load_json_from_lib(nome_file, local = False):\n",
        "    # Usa __file__ per ottenere il percorso della directory del file corrente\n",
        "    if not local:\n",
        "        file_path = os.path.join(os.path.dirname(__file__), nome_file)\n",
        "    else:\n",
        "        file_path = nome_file\n",
        "    with open(file_path, 'r') as file:\n",
        "        return json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Append the parent directory to sys.path\n",
        "sys.path.append(os.path.abspath('..'))\n",
        "\n",
        "# Now you can import the module\n",
        "from llm_utils import api_keys\n",
        "api_keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFiydk4rsvf2"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\\n<<<<<<<<<<<<< No-RAG Reply >>>>>>>>>>>>>>>\")\n",
        "GROQ_API_KEY = api_keys[\"groq\"]\n",
        "MODEL = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
        "# MODEL = \"llama-3.1-8b-instant\"\n",
        "\n",
        "# Test Native LLM response\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "question = \"What is the capital of France?\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ],\n",
        "    stream=False\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "print(\"<<< ----------------- >>>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYhnzH9MwJIQ"
      },
      "source": [
        "# Cose mie da qua"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXwQjuGgwMt_",
        "outputId": "bb8c5a54-93a4-42de-fbf2-cf5e60fdd2f4"
      },
      "outputs": [],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "HdcXYTT9xL9d",
        "outputId": "bab24612-2c89-43cb-bfce-6f6a847a3312"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset_df = pd.read_csv(\"../datasets/working_dataset_1000.csv\")\n",
        "dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT7cgCqkzAlK",
        "outputId": "7d729827-73a2-4339-cb2f-8f00c8d9b3d4"
      },
      "outputs": [],
      "source": [
        "dataset_df['TOPIC_LABEL'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf7YePG1xZF1"
      },
      "outputs": [],
      "source": [
        "# df_FOODAL = dataset_df[dataset_df[\"TOPIC_LABEL\"] == [\"FOODAL\"]]\n",
        "# df_OBWCCE = dataset_df[dataset_df[\"TOPIC_LABEL\"] == [\"OBWCCE\"]]\n",
        "# df_EATBTS = dataset_df[dataset_df[\"TOPIC_LABEL\"] == [\"EATBTS\"]]\n",
        "\n",
        "df_FOODAL = dataset_df[dataset_df['TOPIC_LABEL'].apply(lambda x: 'FOODAL' in x)]\n",
        "df_OBWCCE = dataset_df[dataset_df['TOPIC_LABEL'].apply(lambda x: 'OBWCCE' in x)]\n",
        "df_EATBTS = dataset_df[dataset_df['TOPIC_LABEL'].apply(lambda x: 'EATBTS' in x)]\n",
        "df_VITMIN = dataset_df[dataset_df['TOPIC_LABEL'].apply(lambda x: 'VITMIN' in x)]\n",
        "df_FOODIN = dataset_df[dataset_df['TOPIC_LABEL'].apply(lambda x: 'FOODIN' in x)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB1f-m2LzsoI"
      },
      "outputs": [],
      "source": [
        "working_dir = \"/content/drive/MyDrive/workshop-ECAI/\"\n",
        "working_dir = os.getcwd() + \"/documents_from_working_dataset/\"\n",
        "df_FOODAL.sample(5)['RESULTS'].to_json(working_dir+\"foodal.json\", orient=\"records\")\n",
        "df_OBWCCE.sample(5)['RESULTS'].to_json(working_dir+\"obwcce.json\", orient=\"records\")\n",
        "df_EATBTS.sample(5)['RESULTS'].to_json(working_dir+\"eatbts.json\", orient=\"records\")\n",
        "df_VITMIN.sample(5)['RESULTS'].to_json(working_dir+\"vitmin.json\", orient=\"records\")\n",
        "df_FOODIN.sample(5)['RESULTS'].to_json(working_dir+\"foodin.json\", orient=\"records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz3HMz7oz4qq",
        "outputId": "e27b5a45-8040-46b2-be44-bd2d52b2a96c"
      },
      "outputs": [],
      "source": [
        "# prompt: read a json file and count the element\n",
        "import json\n",
        "\n",
        "working_dir = os.getcwd() + \"/documents_from_working_dataset/\"\n",
        "file_path = working_dir+\"foodal.json\"  # Replace with the actual path to your JSON file\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "  data = json.load(file)\n",
        "\n",
        "# Assuming the JSON file contains a list or a dictionary\n",
        "if isinstance(data, list):\n",
        "  element_count = len(data)\n",
        "  print(f\"The JSON file contains {element_count} elements in the list.\")\n",
        "elif isinstance(data, dict):\n",
        "  element_count = len(data)\n",
        "  print(f\"The JSON file contains {element_count} key-value pairs in the dictionary.\")\n",
        "else:\n",
        "  print(\"The JSON file does not contain a list or a dictionary at the top level.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu8Y_gpD3PiI"
      },
      "outputs": [],
      "source": [
        "role_PROMPT = \"\"\"\n",
        "      You are a helpful assistant responsible for generating evaluation questions\n",
        "      from a given corpus using a structured procedure.\"\"\"\n",
        "goal_PROMPT = \"\"\"\n",
        "      Given a corpus description and the parameters K (number of users), N (number of tasks per user),\n",
        "      and M (number of high-level questions per (user, task) pair), your task is to generate high-level questions\n",
        "      that assess global understanding of the corpus.\n",
        "      \"\"\"\n",
        "generation_step_PROMPT = \"\"\"\n",
        "      Your generation should follow these steps:\n",
        "      1. Create K user personas based on the corpus, including their role/background and motivation for using the corpus.\n",
        "      2. For each user, define N realistic and relevant tasks they would perform using the corpus.\n",
        "      3. For each (user, task) pair, generate M high-level questions that:\n",
        "          - Require comprehensive understanding of the whole corpus.\n",
        "          - Do NOT depend on low-level facts or specific data points (e.g., names, dates, figures).\"\"\"\n",
        "\n",
        "output_PROMPT = \"\"\"\n",
        "      User 1: [Persona description]\n",
        "      Task 1:\n",
        "      Q1. ...\n",
        "      Q2. ...\n",
        "      ...\n",
        "      Task 2:\n",
        "      Q1. ...\n",
        "      ...\n",
        "      User 2: ...\n",
        "      ...\n",
        "      User K: ...\"\"\"\n",
        "\n",
        "output_format_PROMPT = \"\"\"\n",
        "      {{\n",
        "        \"corpus_description\": \"<your summary of the corpus>\",\n",
        "        \"generated_questions\": \"<your structured output as described above>\"\n",
        "      }}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWOHvw762McB"
      },
      "outputs": [],
      "source": [
        "def generate_questions(corpus_description, K, N, M):\n",
        "  PROMPT = f\"\"\"\n",
        "  ---Role--\n",
        "  {role_PROMPT}\n",
        "\n",
        "  ---Goal--\n",
        "  {goal_PROMPT}\n",
        "\n",
        "  {generation_step_PROMPT}\n",
        "\n",
        "  Your output should be structured as follows:\n",
        "  {output_PROMPT}\n",
        "\n",
        "  Format your response as a JSON object with the following structure:\n",
        "  {output_format_PROMPT}\n",
        "\n",
        "  ---Corpus Description--\n",
        "  {corpus_description}\n",
        "  ---Parameters--\n",
        "  Number of Users (K): {K}\n",
        "  Tasks per User (N): {N}\n",
        "  Questions per (User, Task) (M): {M}\n",
        "\n",
        "  Output:\n",
        "  \"\"\"\n",
        "  return PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrSlx6kx9r0k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "MODEL = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
        "GROQ_API_KEY = \"***\"\n",
        "GROQ_API_KEY = api_keys[\"groq\"]\n",
        "\n",
        "client = Groq(\n",
        "    api_key=GROQ_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX-4q8NbaIgO"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/workshop-ECAI/groq_api.txt', 'w') as f:\n",
        "  f.write(GROQ_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuSS3c27Lx-P"
      },
      "outputs": [],
      "source": [
        "working_dir = \"/content/drive/MyDrive/workshop-ECAI/\"\n",
        "working_dir = os.getcwd() + \"/documents_from_working_dataset/\"\n",
        "foodal_docs = json.load(open(working_dir+\"foodal.json\"))\n",
        "obwcce_docs = json.load(open(working_dir+\"obwcce.json\"))\n",
        "eatbts_docs = json.load(open(working_dir+\"eatbts.json\"))\n",
        "vitmin_docs = json.load(open(working_dir+\"vitmin.json\"))\n",
        "foodin_docs = json.load(open(working_dir+\"foodin.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcZLpQPYMAy_",
        "outputId": "9b998198-7c31-4e35-bfde-6885b91ebb12"
      },
      "outputs": [],
      "source": [
        "corpus_description_PROMPT = f\"\"\"\n",
        "---Role--\n",
        "You are a helpful assistant tasked with generating a description of a corpus based on the results of 5 randomly selected academic papers.\n",
        "\n",
        "---Goal--\n",
        "Given a set of 5 academic papers, your task is to summarize the key findings from each paper and combine this information into a coherent corpus description. The description should highlight common themes, methodologies used, and major conclusions drawn across the papers.\n",
        "\n",
        "---Papers---\n",
        "1. {foodin_docs[0]}\n",
        "2. {foodin_docs[1]}\n",
        "3. {foodin_docs[2]}\n",
        "4. {foodin_docs[3]}\n",
        "5. {foodin_docs[4]}\n",
        "\n",
        "---Instructions---\n",
        "For each paper:\n",
        "- Briefly summarize the study's objective.\n",
        "- Describe the methodology used.\n",
        "- List the main findings or results.\n",
        "\n",
        "After analyzing all 5 papers:\n",
        "- Identify common themes across the papers.\n",
        "- Highlight any significant differences in methodologies or results.\n",
        "- Provide an overall description of the corpus that reflects the combined knowledge and insights from the papers.\n",
        "\n",
        "---Output Format---\n",
        "Return your response as a single text object with the following structure:\n",
        "\n",
        "<Detailed description of the corpus based on the 5 papers>\n",
        "\n",
        "---Output---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": corpus_description_PROMPT\n",
        "        }\n",
        "    ],\n",
        "    model=MODEL,\n",
        ")\n",
        "\n",
        "answer = chat_completion.choices[0].message.content\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPLKFSSNN7UB",
        "outputId": "d242af07-e6b7-4bd7-93c4-a35892f47cda"
      },
      "outputs": [],
      "source": [
        "# prompt: write the foodal_answer in a file text in my folder in drive\n",
        "\n",
        "corpus_description = answer.split(\"SNVs, indels, and copy number variants.\\n\\n\")[1]\n",
        "print(corpus_description)\n",
        "\n",
        "with open(working_dir+'foodin_answer.txt', 'w') as f:\n",
        "  f.write(corpus_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbgL0ElyQyAP"
      },
      "source": [
        "# Question Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2O_-ffVwK43",
        "outputId": "b631ebbc-d9e2-4ba7-cbb2-2c0f23f9d4bf"
      },
      "outputs": [],
      "source": [
        "K = 3\n",
        "N = 5\n",
        "M = 5\n",
        "working_dir = \"/content/drive/MyDrive/workshop-ECAI/\"\n",
        "working_dir = os.getcwd() + \"/documents_from_working_dataset/\"\n",
        "with open(working_dir+'foodin_answer.txt', 'r') as file:\n",
        "  corpus_description = file.read()\n",
        "\n",
        "prompt = generate_questions(corpus_description, K, N, M)\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "    ],\n",
        "    model=MODEL,\n",
        ")\n",
        "\n",
        "answer = chat_completion.choices[0].message.content\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHJQboBD1UiL"
      },
      "outputs": [],
      "source": [
        "question_dir = os.getcwd() + \"/questions_files/\"\n",
        "with open(question_dir+'foodin_generated_question.txt', 'w') as f:\n",
        "  f.write(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK5-N_u6SuSk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82eZDMxeSvn3"
      },
      "source": [
        "# Restructuring questions in a DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykxVRxq9S1Nc"
      },
      "outputs": [],
      "source": [
        "question_dir = os.getcwd() + \"/questions_files/\"\n",
        "\n",
        "with open(question_dir+'foodal_generated_question.txt', 'r') as file:\n",
        "  foodal_questions = file.read()\n",
        "\n",
        "with open(question_dir+'obwcce_generated_question.txt', 'r') as file:\n",
        "  obwcce_questions = file.read()\n",
        "\n",
        "with open(question_dir+'eatbts_generated_question.txt', 'r') as file:\n",
        "  eatbts_questions = file.read()\n",
        "\n",
        "with open(question_dir+'vitmin_generated_question.txt', 'r') as file:\n",
        "  vitmin_questions = file.read()\n",
        "\n",
        "with open(question_dir+'foodin_generated_question.txt', 'r') as file:\n",
        "  foodin_questions = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "toNX4nt_S9FK",
        "outputId": "89223218-1ff5-44a5-d5a1-4112724ef458"
      },
      "outputs": [],
      "source": [
        "print(foodal_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0eSkhwcTX0c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Step 1: Read file as plain text\n",
        "#-- Fatto nella cella sopra per tutti\n",
        "\n",
        "questions = [foodin_questions, foodal_questions, obwcce_questions, eatbts_questions, vitmin_questions]\n",
        "categories = [\"FOODIN\", \"FOODAL\", \"OBWCCE\", \"EATBTS\", \"VITMIN\"]\n",
        "\n",
        "data = {}\n",
        "\n",
        "for i, q in enumerate(questions):\n",
        "\n",
        "    # Step 2: Manually extract the 'generated_questions' content\n",
        "    match = re.search(r'\"generated_questions\"\\s*:\\s*\"(?P<content>.*)\"\\s*}', q, re.DOTALL)\n",
        "    if not match:\n",
        "        raise ValueError(\"Could not find 'generated_questions' content in the file.\")\n",
        "\n",
        "    content = match.group(\"content\")\n",
        "\n",
        "    # Step 3: Unescape escaped quotes and normalize the content\n",
        "    content = content.replace('\\\\\"', '\"')\n",
        "\n",
        "    # Step 4: Parse lines\n",
        "    lines = content.splitlines()\n",
        "\n",
        "\n",
        "    category = categories[i]  # or derive from file name\n",
        "    print(f\"Processing category: {category}\")\n",
        "\n",
        "    rows = []\n",
        "    current_user = None\n",
        "    current_task = None\n",
        "    questions = []\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        if line.startswith(\"User\"):\n",
        "            current_user = line.split(\":\", 1)[1].strip()\n",
        "        elif line.startswith(\"Task\"):\n",
        "            if current_task and questions:\n",
        "                rows.append({\n",
        "                    \"Category\": category,\n",
        "                    \"USER Description\": current_user,\n",
        "                    \"TASK Description\": current_task,\n",
        "                    \"Questions\": questions\n",
        "                })\n",
        "                questions = []\n",
        "            current_task = line.split(\":\", 1)[1].strip()\n",
        "        elif re.match(r\"Q\\d+\\.\", line):\n",
        "            questions.append(line)\n",
        "\n",
        "    # Append the last block\n",
        "    if current_task and questions:\n",
        "        rows.append({\n",
        "            \"Category\": category,\n",
        "            \"USER Description\": current_user,\n",
        "            \"TASK Description\": current_task,\n",
        "            \"Questions\": questions\n",
        "        })\n",
        "    \n",
        "    data[category] = rows\n",
        "\n",
        "# Step 5: Create DataFrame\n",
        "# df_foodin = pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "bDD92uF_WmmB",
        "outputId": "a41b1874-02fd-46fa-f306-b7a29c263de1"
      },
      "outputs": [],
      "source": [
        "df_foodal = pd.DataFrame(data[\"FOODAL\"])\n",
        "df_obwcce = pd.DataFrame(data[\"OBWCCE\"])\n",
        "df_eatbts = pd.DataFrame(data[\"EATBTS\"])\n",
        "df_vitmin = pd.DataFrame(data[\"VITMIN\"])\n",
        "df_foodin = pd.DataFrame(data[\"FOODIN\"])\n",
        "df_foodal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW-UDhrIWnfD"
      },
      "outputs": [],
      "source": [
        "# prompt: append all these dataframe together: df_foodal\n",
        "# df_obwcce\n",
        "# df_eatbts\n",
        "# df_vitmin\n",
        "# df_foodin\n",
        "\n",
        "df_combined = pd.concat([df_foodal, df_obwcce, df_eatbts, df_vitmin, df_foodin], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3RjtCnBXdco"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_combined.to_pickle(\"questions_dataframe.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDz9WfO9Xo3Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
