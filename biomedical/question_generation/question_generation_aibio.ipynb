{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTtgAV8RtWiO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qns5kcqhtSK4"
      },
      "outputs": [],
      "source": [
        "def load_json_from_lib(nome_file, local = False):\n",
        "    # Usa __file__ per ottenere il percorso della directory del file corrente\n",
        "    if not local:\n",
        "        file_path = os.path.join(os.path.dirname(__file__), nome_file)\n",
        "    else:\n",
        "        file_path = nome_file\n",
        "    with open(file_path, 'r') as file:\n",
        "        return json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Append the parent directory to sys.path\n",
        "sys.path.append(os.path.abspath('..'))\n",
        "\n",
        "# Now you can import the module\n",
        "from llm_utils import api_keys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFiydk4rsvf2"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\\n<<<<<<<<<<<<< No-RAG Reply >>>>>>>>>>>>>>>\")\n",
        "GROQ_API_KEY = api_keys[\"groq\"]\n",
        "print(\"GROQ_API_KEY:\", GROQ_API_KEY)\n",
        "MODEL = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
        "# MODEL = \"llama-3.1-8b-instant\"\n",
        "\n",
        "# Test Native LLM response\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "question = \"What is the capital of France?\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ],\n",
        "    stream=False\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "print(\"<<< ----------------- >>>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYhnzH9MwJIQ"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXwQjuGgwMt_",
        "outputId": "bb8c5a54-93a4-42de-fbf2-cf5e60fdd2f4"
      },
      "outputs": [],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "HdcXYTT9xL9d",
        "outputId": "bab24612-2c89-43cb-bfce-6f6a847a3312"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset_df = pd.read_csv(\"../datasets/working_dataset_1000.csv\")\n",
        "dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT7cgCqkzAlK",
        "outputId": "7d729827-73a2-4339-cb2f-8f00c8d9b3d4"
      },
      "outputs": [],
      "source": [
        "dataset_df['TOPIC_LABEL'].unique()\n",
        "\n",
        "default_entity_types = [\n",
        "    \"Gene\",\n",
        "    \"Genetic Variant\",\n",
        "    \"Transcript\",\n",
        "    \"Protein\",\n",
        "    \"Nutrient\",\n",
        "    \"Food\",\n",
        "    \"Dietary Pattern\",\n",
        "    \"Physiological Process\",\n",
        "    \"Metabolic Pathway\",\n",
        "    \"Molecular Interaction\",\n",
        "    \"Environmental Factor\",\n",
        "    \"Disease\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf7YePG1xZF1"
      },
      "outputs": [],
      "source": [
        "# df_FOODAL = dataset_df[dataset_df[\"TOPIC_LABEL\"] == [\"FOODAL\"]]\n",
        "# df_OBWCCE = dataset_df[dataset_df[\"TOPIC_LABEL\"] == [\"OBWCCE\"]]\n",
        "# df_EATBTS = dataset_df[dataset_df[\"TOPIC_LABEL\"] == [\"EATBTS\"]]\n",
        "\n",
        "df_FOODAL = dataset_df[dataset_df['TOPIC_LABEL'].apply(lambda x: 'FOODAL' in x)]\n",
        "df_OBWCCE = dataset_df[dataset_df['TOPIC_LABEL'].apply(lambda x: 'OBWCCE' in x)]\n",
        "df_EATBTS = dataset_df[dataset_df['TOPIC_LABEL'].apply(lambda x: 'EATBTS' in x)]\n",
        "df_VITMIN = dataset_df[dataset_df['TOPIC_LABEL'].apply(lambda x: 'VITMIN' in x)]\n",
        "df_FOODIN = dataset_df[dataset_df['TOPIC_LABEL'].apply(lambda x: 'FOODIN' in x)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB1f-m2LzsoI"
      },
      "outputs": [],
      "source": [
        "working_dir = \"/content/drive/MyDrive/workshop-ECAI/\"\n",
        "working_dir = os.getcwd() + \"/documents_from_working_dataset/\"\n",
        "df_FOODAL.sample(5)['RESULTS'].to_json(working_dir+\"foodal.json\", orient=\"records\")\n",
        "df_OBWCCE.sample(5)['RESULTS'].to_json(working_dir+\"obwcce.json\", orient=\"records\")\n",
        "df_EATBTS.sample(5)['RESULTS'].to_json(working_dir+\"eatbts.json\", orient=\"records\")\n",
        "df_VITMIN.sample(5)['RESULTS'].to_json(working_dir+\"vitmin.json\", orient=\"records\")\n",
        "df_FOODIN.sample(5)['RESULTS'].to_json(working_dir+\"foodin.json\", orient=\"records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz3HMz7oz4qq",
        "outputId": "e27b5a45-8040-46b2-be44-bd2d52b2a96c"
      },
      "outputs": [],
      "source": [
        "# prompt: read a json file and count the element\n",
        "import json\n",
        "\n",
        "working_dir = os.getcwd() + \"/documents_from_working_dataset/\"\n",
        "file_path = working_dir+\"foodal.json\"  # Replace with the actual path to your JSON file\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "  data = json.load(file)\n",
        "\n",
        "# Assuming the JSON file contains a list or a dictionary\n",
        "if isinstance(data, list):\n",
        "  element_count = len(data)\n",
        "  print(f\"The JSON file contains {element_count} elements in the list.\")\n",
        "elif isinstance(data, dict):\n",
        "  element_count = len(data)\n",
        "  print(f\"The JSON file contains {element_count} key-value pairs in the dictionary.\")\n",
        "else:\n",
        "  print(\"The JSON file does not contain a list or a dictionary at the top level.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mychatgpt import bot\n",
        "men = bot(\"mendel\",model=4)\n",
        "m='''You have to bias this prompt, toward Biomedical entities and context on this entities relationship. \n",
        "This are the entities of our KNowledge Graph\n",
        "default_entity_types = [\n",
        "    \"Gene\",\n",
        "    \"Genetic Variant\",\n",
        "    \"Transcript\",\n",
        "    \"Protein\",\n",
        "    \"Nutrient\",\n",
        "    \"Food\",\n",
        "    \"Dietary Pattern\",\n",
        "    \"Physiological Process\",\n",
        "    \"Metabolic Pathway\",\n",
        "    \"Molecular Interaction\",\n",
        "    \"Environmental Factor\",\n",
        "    \"Disease\",\n",
        "]\n",
        "\n",
        "This is part of a script for question generation that will be used to generate high-level questions for a corpus of genetic  documents realted to nutrition (nutrigentics).\n",
        "\n",
        "goal_PROMPT = \"\"\" Given a corpus description and the parameters K (number of users), N (number of tasks per user), and M (number of high-level questions per (user, task) pair), your task is to generate high-level questions that assess global understanding of the corpus.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "'''\n",
        "men.c(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu8Y_gpD3PiI"
      },
      "outputs": [],
      "source": [
        "role_PROMPT = \"\"\"\n",
        "      You are a helpful assistant responsible for generating evaluation questions\n",
        "      from a given corpus using a structured procedure.\n",
        "      \n",
        "      In the context of nutrigenetics, where we analyze the interactions between genetic variants and nutritional elements, your task is to generate high-level questions focusing on the complex relationships and effects among the following entities: Gene, Genetic Variant, Transcript, Protein, Nutrient, Food, Dietary Pattern, Physiological Process, Metabolic Pathway, Molecular Interaction, Environmental Factor, and Disease. These questions should aim to deepen the global understanding of how nutritional factors interact with genetic makeup to influence health and disease outcomes.\n",
        "      \"\"\"\n",
        "# goal_PROMPT = \"\"\"\n",
        "#       Given a corpus description and the parameters K (number of users), N (number of tasks per user),\n",
        "#       and M (number of high-level questions per (user, task) pair), your task is to generate high-level questions\n",
        "#       that assess global understanding of the corpus.\n",
        "#       \"\"\"\n",
        "goal_PROMPT = \"\"\"\n",
        "Given a corpus description and the parameters K (number of users), N (number of tasks per user), and M (number of high-level questions per (user, task) pair), your task is to craft questions that illuminate the interconnectedness and impact of these biomedical entities. Consider the following angles to guide your question generation:\n",
        "entities: Gene, Genetic Variant, Transcript, Protein, Nutrient, Food, Dietary Pattern, Physiological Process, Metabolic Pathway, Molecular Interaction, Environmental Factor, and Disease. These questions should aim to deepen the global understanding of how nutritional factors interact with genetic makeup to influence health and disease outcomes.\n",
        "\n",
        "Your questions should explore the following themes:\n",
        "1. **Genomic Influence on Nutrition:** How do specific genetic variants influence individual responses to nutrients and dietary patterns? Explore effects on metabolic pathways and physiological processes.\n",
        "\n",
        "2. **Nutritional Impact on Gene Expression:** In what ways do particular nutrients or dietary patterns affect gene expression, transcript production, and protein synthesis? Assess the downstream impact on health and disease.\n",
        "\n",
        "3. **Disease and Genetic-Nutrient Interactions:** How do dietary factors interact with genes to modulate disease risk or progression? Consider molecular interactions and potential environmental influences.\n",
        "\n",
        "4. **Metabolic Pathway Insights:** What roles do metabolic pathways and molecular interactions play in mediating the effects of nutrition-genetic interactions on physiological processes and disease outcomes?\n",
        "\n",
        "5. **Environmental and Nutrient Modulation:** How do environmental factors alter the interactions between genes and nutrients, potentially influencing health outcomes and disease susceptibility? \n",
        "\n",
        "Your questions should endeavor to connect these entities within a comprehensive framework that reflects the complexity of nutrigenomic research, fostering a robust understanding of the underlying biological mechanisms.ticError\n",
        "\n",
        "\"\"\"\n",
        "# generation_step_PROMPT = \"\"\"\n",
        "#       Your generation should follow these steps:\n",
        "#       1. Create K user personas based on the corpus, including their role/background and motivation for using the corpus.\n",
        "#       2. For each user, define N realistic and relevant tasks they would perform using the corpus.\n",
        "#       3. For each (user, task) pair, generate M high-level questions that:\n",
        "#           - Require comprehensive understanding of the whole corpus.\n",
        "#           - Do NOT depend on low-level facts or specific data points (e.g., names, dates, figures).\"\"\"\n",
        "\n",
        "generation_step_PROMPT = \"\"\"\n",
        "      Your generation should follow these steps:\n",
        "      1. Create 3 user personas based on the corpus, including their role/background and motivation for using the corpus.\n",
        "            user 1: a researcher in nutrigenetics, interested in understanding how genetic variants influence dietary responses.\n",
        "            user 2: a healthcare professional looking to apply nutrigenetic insights in clinical practice.\n",
        "            user 3: a customer interested in personalized nutrition based on genetic information.\n",
        "      2. For each user, define N realistic and relevant tasks they would perform using the corpus.\n",
        "      3. For each (user, task) pair, generate M high-level questions that:\n",
        "          - Require comprehensive understanding of the whole corpus.\n",
        "          - Do NOT depend on low-level facts or specific data points (e.g., names, dates, figures).\"\"\"\n",
        "output_PROMPT = \"\"\"\n",
        "      User 1: [Persona description]\n",
        "      Task 1:\n",
        "      Q1. ...\n",
        "      Q2. ...\n",
        "      ...\n",
        "      Task 2:\n",
        "      Q1. ...\n",
        "      ...\n",
        "      User 2: ...\n",
        "      ...\n",
        "      User K: ...\"\"\"\n",
        "\n",
        "output_format_PROMPT = \"\"\"\n",
        "      {{\n",
        "        \"corpus_description\": \"<your summary of the corpus>\",\n",
        "        \"generated_questions\": \"<your structured output as described above>\"\n",
        "      }}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWOHvw762McB"
      },
      "outputs": [],
      "source": [
        "def generate_questions(corpus_description, K, N, M):\n",
        "  PROMPT = f\"\"\"\n",
        "  ---Role--\n",
        "  {role_PROMPT}\n",
        "\n",
        "  ---Goal--\n",
        "  {goal_PROMPT}\n",
        "\n",
        "  {generation_step_PROMPT}\n",
        "\n",
        "  Your output should be structured as follows:\n",
        "  {output_PROMPT}\n",
        "\n",
        "  Format your response as a JSON object with the following structure:\n",
        "  {output_format_PROMPT}\n",
        "\n",
        "  ---Corpus Description--\n",
        "  {corpus_description}\n",
        "  ---Parameters--\n",
        "  Number of Users (K): {K}\n",
        "  Tasks per User (N): {N}\n",
        "  Questions per (User, Task) (M): {M}\n",
        "\n",
        "  Output:\n",
        "  \"\"\"\n",
        "  return PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrSlx6kx9r0k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "MODEL = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
        "GROQ_API_KEY = \"***\"\n",
        "GROQ_API_KEY = api_keys[\"groq\"]\n",
        "\n",
        "client = Groq(\n",
        "    api_key=GROQ_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX-4q8NbaIgO"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/workshop-ECAI/groq_api.txt', 'w') as f:\n",
        "  f.write(GROQ_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuSS3c27Lx-P"
      },
      "outputs": [],
      "source": [
        "working_dir = \"/content/drive/MyDrive/workshop-ECAI/\"\n",
        "working_dir = os.getcwd() + \"/documents_from_working_dataset/\"\n",
        "foodal_docs = json.load(open(working_dir+\"foodal.json\"))\n",
        "obwcce_docs = json.load(open(working_dir+\"obwcce.json\"))\n",
        "eatbts_docs = json.load(open(working_dir+\"eatbts.json\"))\n",
        "vitmin_docs = json.load(open(working_dir+\"vitmin.json\"))\n",
        "foodin_docs = json.load(open(working_dir+\"foodin.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcZLpQPYMAy_",
        "outputId": "9b998198-7c31-4e35-bfde-6885b91ebb12"
      },
      "outputs": [],
      "source": [
        "docs_list = [foodal_docs, obwcce_docs, eatbts_docs, vitmin_docs, foodin_docs]\n",
        "labels = [\"foodal\", \"obwcce\", \"eatbts\", \"vitmin\", \"foodin\"]\n",
        "\n",
        "for i, doc in enumerate(docs_list):\n",
        "    corpus_description_PROMPT = f\"\"\"\n",
        "    ---Role--\n",
        "    You are a helpful assistant tasked with generating a description of a corpus based on the results of 5 randomly selected academic papers.\n",
        "\n",
        "    ---Goal--\n",
        "    Given a set of 5 academic papers, your task is to summarize the key findings from each paper and combine this information into a coherent corpus description. The description should highlight common themes, methodologies used, and major conclusions drawn across the papers.\n",
        "\n",
        "    ---Context--\n",
        "    In the context of nutrigenetics, where we analyze the interactions between genetic variants and nutritional elements, your task is to generate high-level questions focusing on the complex relationships and effects among the following entities: Gene, Genetic Variant, Transcript, Protein, Nutrient, Food, Dietary Pattern, Physiological Process, Metabolic Pathway, Molecular Interaction, Environmental Factor, and Disease. These questions should aim to deepen the global understanding of how nutritional factors interact with genetic makeup to influence health and disease outcomes.\n",
        "\n",
        "    ---Papers---\n",
        "    1. {doc[0]}\n",
        "    2. {doc[1]}\n",
        "    3. {doc[2]}\n",
        "    4. {doc[3]}\n",
        "    5. {doc[4]}\n",
        "\n",
        "    ---Instructions---\n",
        "    For each paper:\n",
        "    - Briefly summarize the study's objective.\n",
        "    - Describe the methodology used.\n",
        "    - List the main findings or results highlighting biomedical entities.\n",
        "\n",
        "    After analyzing all 5 papers:\n",
        "    - Identify common themes across the papers.\n",
        "    - Highlight any significant differences in methodologies or results.\n",
        "    - Provide an overall description of the corpus that reflects the combined knowledge and insights from the papers.\n",
        "\n",
        "    ---Output Format---\n",
        "    Return your response as a single text object with the following structure:\n",
        "\n",
        "    <Detailed description of the corpus based on the 5 papers>\n",
        "\n",
        "    ---Output---\n",
        "    **Corpus Description**\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": corpus_description_PROMPT\n",
        "            }\n",
        "        ],\n",
        "        model=MODEL,\n",
        "    )\n",
        "\n",
        "    answer = chat_completion.choices[0].message.content\n",
        "\n",
        "    # print(answer)\n",
        "\n",
        "\n",
        "    # prompt: write the foodal_answer in a file text in my folder in drive\n",
        "\n",
        "    corpus_description = answer.split(\"**\")[-1]\n",
        "    print(corpus_description)\n",
        "\n",
        "    with open(working_dir+f'{labels[i]}_answer.txt', 'w') as f:\n",
        "       f.write(corpus_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbgL0ElyQyAP"
      },
      "source": [
        "# Question Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2O_-ffVwK43",
        "outputId": "b631ebbc-d9e2-4ba7-cbb2-2c0f23f9d4bf"
      },
      "outputs": [],
      "source": [
        "K = 3\n",
        "N = 5\n",
        "M = 5\n",
        "# working_dir = \"/content/drive/MyDrive/workshop-ECAI/\"\n",
        "working_dir = os.getcwd() + \"/documents_from_working_dataset/\"\n",
        "\n",
        "docs_list = [foodal_docs, obwcce_docs, eatbts_docs, vitmin_docs, foodin_docs]\n",
        "labels = [\"foodal\", \"obwcce\", \"eatbts\", \"vitmin\", \"foodin\"]\n",
        "\n",
        "for i, doc in enumerate(docs_list):\n",
        "  with open(working_dir+f'{labels[i]}_answer.txt', 'r') as file:\n",
        "    corpus_description = file.read()\n",
        "\n",
        "  prompt = generate_questions(corpus_description, K, N, M)\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt\n",
        "          }\n",
        "      ],\n",
        "      model=MODEL,\n",
        "  )\n",
        "\n",
        "  answer = chat_completion.choices[0].message.content\n",
        "\n",
        "  print(answer)\n",
        "\n",
        "  question_dir = os.getcwd() + \"/questions_files/\"\n",
        "  with open(question_dir+f'{labels[i]}_generated_question.txt', 'w') as f:\n",
        "    f.write(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK5-N_u6SuSk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82eZDMxeSvn3"
      },
      "source": [
        "# Restructuring questions in a DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykxVRxq9S1Nc"
      },
      "outputs": [],
      "source": [
        "question_dir = os.getcwd() + \"/questions_files/\"\n",
        "\n",
        "with open(question_dir+'foodal_generated_question.txt', 'r') as file:\n",
        "  foodal_questions = file.read()\n",
        "\n",
        "with open(question_dir+'obwcce_generated_question.txt', 'r') as file:\n",
        "  obwcce_questions = file.read()\n",
        "\n",
        "with open(question_dir+'eatbts_generated_question.txt', 'r') as file:\n",
        "  eatbts_questions = file.read()\n",
        "\n",
        "with open(question_dir+'vitmin_generated_question.txt', 'r') as file:\n",
        "  vitmin_questions = file.read()\n",
        "\n",
        "with open(question_dir+'foodin_generated_question.txt', 'r') as file:\n",
        "  foodin_questions = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "toNX4nt_S9FK",
        "outputId": "89223218-1ff5-44a5-d5a1-4112724ef458"
      },
      "outputs": [],
      "source": [
        "print(foodal_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0eSkhwcTX0c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Step 1: Read file as plain text\n",
        "#-- Fatto nella cella sopra per tutti\n",
        "\n",
        "questions = [foodin_questions, foodal_questions, obwcce_questions, eatbts_questions, vitmin_questions]\n",
        "categories = [\"FOODIN\", \"FOODAL\", \"OBWCCE\", \"EATBTS\", \"VITMIN\"]\n",
        "\n",
        "data = {}\n",
        "\n",
        "for i, q in enumerate(questions):\n",
        "\n",
        "    # Step 2: Manually extract the 'generated_questions' content\n",
        "    match = re.search(r'\"generated_questions\"\\s*:\\s*\"(?P<content>.*)\"\\s*}', q, re.DOTALL)\n",
        "    if not match:\n",
        "        raise ValueError(\"Could not find 'generated_questions' content in the file.\")\n",
        "\n",
        "    content = match.group(\"content\")\n",
        "\n",
        "    # Step 3: Unescape escaped quotes and normalize the content\n",
        "    content = content.replace('\\\\\"', '\"')\n",
        "\n",
        "    # Step 4: Parse lines\n",
        "    lines = content.splitlines()\n",
        "\n",
        "\n",
        "    category = categories[i]  # or derive from file name\n",
        "    print(f\"Processing category: {category}\")\n",
        "\n",
        "    rows = []\n",
        "    current_user = None\n",
        "    current_task = None\n",
        "    questions = []\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        if line.startswith(\"User\"):\n",
        "            current_user = line.split(\":\", 1)[1].strip()\n",
        "        elif line.startswith(\"Task\"):\n",
        "            if current_task and questions:\n",
        "                rows.append({\n",
        "                    \"Category\": category,\n",
        "                    \"USER Description\": current_user,\n",
        "                    \"TASK Description\": current_task,\n",
        "                    \"Questions\": questions\n",
        "                })\n",
        "                questions = []\n",
        "            current_task = line.split(\":\", 1)[1].strip()\n",
        "        elif re.match(r\"Q\\d+\\.\", line):\n",
        "            questions.append(line)\n",
        "\n",
        "    # Append the last block\n",
        "    if current_task and questions:\n",
        "        rows.append({\n",
        "            \"Category\": category,\n",
        "            \"USER Description\": current_user,\n",
        "            \"TASK Description\": current_task,\n",
        "            \"Questions\": questions\n",
        "        })\n",
        "    \n",
        "    data[category] = rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "bDD92uF_WmmB",
        "outputId": "a41b1874-02fd-46fa-f306-b7a29c263de1"
      },
      "outputs": [],
      "source": [
        "# Step 5: Create DataFrame\n",
        "df_foodal = pd.DataFrame(data[\"FOODAL\"])\n",
        "df_obwcce = pd.DataFrame(data[\"OBWCCE\"])\n",
        "df_eatbts = pd.DataFrame(data[\"EATBTS\"])\n",
        "df_vitmin = pd.DataFrame(data[\"VITMIN\"])\n",
        "df_foodin = pd.DataFrame(data[\"FOODIN\"])\n",
        "df_foodal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW-UDhrIWnfD"
      },
      "outputs": [],
      "source": [
        "# prompt: append all these dataframe together: df_foodal\n",
        "\n",
        "df_combined = pd.concat([df_foodal, df_obwcce, df_eatbts, df_vitmin, df_foodin], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3RjtCnBXdco"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_combined.to_pickle(\"questions_dataframe_v3.pkl\")\n",
        "df_combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDz9WfO9Xo3Q"
      },
      "outputs": [],
      "source": [
        "for desc in df_combined['USER Description'].drop_duplicates():\n",
        "    print(desc,\"\\n------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for desc in df_combined['Questions'].drop_duplicates():\n",
        "    print(desc,\"\\n------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for desc in df_combined['TASK Description'].drop_duplicates():\n",
        "    print(desc,\"\\n------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use community report summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "cache_dict ={1: 'cache_llama3.1_8b_all-mpnet-base-v2',\n",
        "             2: 'cache_gemma2_all-mpnet-base-v2',\n",
        "             3: 'cache_qwen2.5_14b_all-mpnet-base-v2',\n",
        "             4: 'cache_qwen2_7b_dmis-lab_biobert-v1.1',\n",
        "             5: 'cache_qwen2_7b_all-mpnet-base-v2',\n",
        "             6: 'cache_qwen2.5_14b_dmis-lab_biobert-v1.1',\n",
        "             7: 'cache_llama3.1_8b_dmis-lab_biobert-v1.1',\n",
        "             8: 'cache_gemma2_dmis-lab_biobert-v1.1'}\n",
        "n = 2\n",
        "# community reports\n",
        "root = os.getcwd()\n",
        "root = \"/root/projects/nano-graphrag/biomedical/ablation_study\"\n",
        "file = os.path.join(root, cache_dict[n], 'kv_store_community_reports.json')\n",
        "print(f\"Loading graph from file: {file}\\n\")\n",
        "\n",
        "with open(file, 'r') as f:\n",
        "    community_reports = json.load(f)\n",
        "\n",
        "# Funzione per estrarre tutti i report con rating > 8 dal file json caricato\n",
        "def extract_high_score_reports(community_reports, threshold=8):\n",
        "    # Ritorna una lista dei valori report_json con rating maggiore della soglia\n",
        "    return [\n",
        "        report_data[\"report_json\"]\n",
        "        for report_data in community_reports.values()\n",
        "        if float(report_data[\"report_json\"][\"rating\"]) > threshold\n",
        "    ]\n",
        "\n",
        "\n",
        "reports = extract_high_score_reports(community_reports, threshold=7)\n",
        "\n",
        "high_score_reports_summary = [report[\"summary\"] for report in reports]\n",
        "len(high_score_reports_summary)\n",
        "\n",
        "# Make 4 list of the from high_score_reports_summary\n",
        "batch_size = 4\n",
        "batches = [high_score_reports_summary[i:i + batch_size] for i in range(0, len(high_score_reports_summary), batch_size)]\n",
        "# for i, batch in enumerate(batches):\n",
        "#     with open(f\"batch_{i+1}_high_score_reports.json\", 'w') as f:\n",
        "#         json.dump(batch, f, indent=4)\n",
        "\n",
        "batches[0]\n",
        "for i, batch in enumerate(batches):\n",
        "    text = \"\\n\\n\".join(batch)\n",
        "\n",
        "text = \"\"\"**Corpus Description**\\n\\n\"\"\"+text\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "K = 3\n",
        "N = 5\n",
        "M = 5\n",
        "# working_dir = \"/content/drive/MyDrive/workshop-ECAI/\"\n",
        "working_dir = os.getcwd() + \"/documents_from_working_dataset/\"\n",
        "\n",
        "answers =[]\n",
        "for i, batch in enumerate(batches):\n",
        "  for i, chunk in enumerate(batch):\n",
        "    text = \"\\n\\n\".join(chunk)\n",
        "\n",
        "  corpus_description = \"\"\"**Corpus Description**\\n\\n\"\"\"+text\n",
        "\n",
        "  corpus_description = batch\n",
        "\n",
        "  prompt = generate_questions(corpus_description, K, N, M)\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt\n",
        "          }\n",
        "      ],\n",
        "      model=MODEL,\n",
        "  )\n",
        "\n",
        "  answer = chat_completion.choices[0].message.content\n",
        "\n",
        "  answers.append(answer)\n",
        "  print(answer)\n",
        "  print(\"<<< ----------------- >>>\")\n",
        "\n",
        "  # question_dir = os.getcwd() + \"/questions_files/\"\n",
        "  # with open(question_dir+f'{labels[i]}_generated_question.txt', 'w') as f:\n",
        "  #   f.write(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import re\n",
        "text = \"\"\" \"\"\"\n",
        "\n",
        "# Extract User and Task information and question block (as a list ) from the input\n",
        "def extract_user_tasks(input_text):\n",
        "    user_tasks = []\n",
        "    lines = input_text.strip().split('\\n')\n",
        "    current_user = None\n",
        "    current_task = None\n",
        "    questions = []\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line.startswith('User'):\n",
        "            if current_user and current_task and questions:\n",
        "                user_tasks.append((current_user, current_task, questions))\n",
        "            # Esxtract the User code (User1, User2, etc.)\n",
        "            current_user = line.split(':')[0].strip()\n",
        "            current_task = None\n",
        "            questions = []\n",
        "        elif line.startswith('Task'):\n",
        "            if current_task and questions:\n",
        "                user_tasks.append((current_user, current_task, questions))\n",
        "            current_task = line.split(':')[1].strip()\n",
        "            questions = []\n",
        "        elif line.startswith('Q'):\n",
        "            questions.append(line)\n",
        "\n",
        "    if current_user and current_task and questions:\n",
        "        user_tasks.append((current_user, current_task, questions))\n",
        "\n",
        "    return user_tasks\n",
        "extract_user_tasks(text)\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(extract_user_tasks(text), columns=['User', 'Task', 'Questions'])\n",
        "df.to_pickle(f'questions_cache_gemma2_all-mpnet-base-v2.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "newenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
